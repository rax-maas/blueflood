# Blueflood
[Discuss](https://groups.google.com/forum/#!forum/blueflood-discuss)
- [Code](http://github.com/rackerlabs/blueflood)
- [Site](http://blueflood.io)

## Introduction

Blueflood is a multi-tenant distributed metric processing system created by engineers at 
[Rackspace](http://www.rackspace.com).
It is used in production by the [Cloud Monitoring](http://www.rackspace.com/cloud/monitoring/)
team to process metrics generated by their monitoring systems.
Blueflood is capable of ingesting, rolling up and serving metrics at a massive scale.

## Getting Started

The latest code will always be here on Github.

    git clone git@github.com:rackerlabs/blueflood.git
    cd blueflood
    
You can run the entire suite of tests using Maven:

    mvn test integration-test

### Building

Build an 'uber jar' using maven:

    mvn package

The uber jar will be found in ${BLUEFLOOD_DIR}/blueflood-all/target/blueflood-all-${VERSION}-jar-with-dependencies.jar.
This jar contains all the dependencies necessary to run Blueflood with a very simple classpath.

### Running

The best place to start is the [10 minute guide](https://github.com/rackerlabs/blueflood/wiki/10minuteguide).
In a nutshell, you must do this:

    java -cp /path/to/uber.jar com.rackspacecloud.blueflood.service.BluefloodServiceStarter \
    -Dblueflood.config=file:///path/to/blueflood.conf \
    -Dlog4j.configuration=file:///path/to/log4j.properties
    
Each configuration option can be found in Configuration.java.  Each of those can be overriden on the command line by
doing:

    -DCONFIG_OPTION=NEW_VALUE

## Development

We anticipate different use cases for Blueflood.  For example, at Rackspace it made more sense to create a
[Thrift](http://thrift.apache.org) layer for ingestion and query.  We have chosen not to release that layer because
it contains a lot of code that is specific to our infrastructure and other backend systems.

We decided to release Blueflood with reference HTTP-based ingestion and query layers.  These layers may be replaced by
code that works better with your enterprise.

### Custom Ingestion

Two things must be done to properly ingest data:
1. Full resolution data must be written via `AstyanaxWriter.insertFull()`.
2. A `ScheduleContext` object must be `update()`d regarding that metrics shard and collection time.
3. Shard state must be periodically pushed to the database for each shard that metrics have been collected for.  This
   can be done by getting the dirty slot information from the `ShardStateManager` associated with a particular
   `ScheduleContext` object.

`HttpMetricsIngestionServer` is an example of how to set up a multi-threaded staged ingestion pipeline.

### Custom Querying

Thankfully, querying is easier than ingestion.  Whatever query service you create should have a handler that extends
`RollupHandler`, which provides a basic wrapping of low level read operations provided by `AstyanaxReader`.

## Operations

Blueflood exposes a great deal of metrics over JMX.  Blueflood respects the standard JMX JVM settings:

    com.sun.management.jmxremote.authenticate
    com.sun.management.jmxremote.ssl
    java.rmi.server.hostname
    com.sun.management.jmxremote.port
    
You can use any tool that supports JMX to get metrics out of Blueflood.

Additionally, metrics can be pushed directly to a Graphite service by specifying the following in your Blueflood
configuration:

    GRAPHITE_HOST
    GRAPHITE_PORT
    GRAPHITE_PREFIX

## Learn More

First, we welcome bug reports and contributions.  We use a Github workflow for dealing with these, so if you are
familiar with that process, you know what to do.

We've set up a [Google Group](https://groups.google.com/forum/#!forum/blueflood-discuss) to answer questions.
If you prefer IRC, most of the Blueflood developers are in #blueflood on Freenode.

